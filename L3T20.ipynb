{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eHGm8RQlK46m"
   },
   "source": [
    "# Get and explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-erlYw1jXtgh"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import statistics\n",
    "import re\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "goZIhX8nII4T"
   },
   "outputs": [],
   "source": [
    "# Make results reproducible - set random seed\n",
    "from numpy.random import seed\n",
    "seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v_fEysQHII4W",
    "tags": []
   },
   "outputs": [],
   "source": [
    "negative_file = \"negative.txt\"\n",
    "positive_file = \"positive.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0rWm4yycII4Y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Do not modify - helper function to load and preprocess data\n",
    "def filter_words(line):    \n",
    "    line = re.sub(r'[^\\w\\s]','',line.rstrip())\n",
    "    words = line.split(\" \") \n",
    "    words = [i.lower() for i in words if i]      \n",
    "    return \" \".join(words)\n",
    "\n",
    "def load_data(filename):\n",
    "    thefile = open(filename, 'r') \n",
    "    lines = thefile.readlines() \n",
    "\n",
    "    data = []\n",
    "    for l in range(0,len(lines)): \n",
    "        if(lines[l-1].strip() == \"<title>\"): \n",
    "            theline = filter_words(lines[l])\n",
    "            if(len(theline) < 50):\n",
    "                data.append(theline)            \n",
    "            \n",
    "    return data\n",
    "\n",
    "# Helper function to convert categorical data to class label\n",
    "def to_word_label(y):\n",
    "    y = to_class(y)   \n",
    "    return [\"positive\" if i==0 else \"negative\" for i in y]\n",
    "\n",
    "# Helper function to convert class label to numeric label\n",
    "def to_numeric_label(y):\n",
    "  return [0 if i==\"positive\" else 1 for i in word_labels]\n",
    "\n",
    "# Helper function: this function needs to be called before sending arrays to sklearn metrics,\n",
    "# it converts back to class form from categorical form. ie: [1,0] --> 0, [0,1] --> 1\n",
    "def to_class(y):\n",
    "    return np.argmax(y,axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "jjGUiFm9II4b",
    "outputId": "aa5eb89b-85f2-4d61-f33a-b00361b19a41",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one of the best crichton novels', 'the medicine of the future', 'beautiful', 'for lovers of robicheaux', 'a good book', 'to the point and beautifully illustrated', 'at least somebody has got it', 'beautifully written heartwarming story', 'an excellent cookbook full of delicious recipes', 'an outstanding resource']\n",
      "['horrible book horrible', 'shallow selfindulgence', 'horrible book horrible', 'disappointment', 'a disappointing mess', 'save your money there are better books out there', 'thank you but no thanks', 'unendurable', 'the hard way', 'some good info among the political commercial']\n"
     ]
    }
   ],
   "source": [
    "positive = load_data(positive_file)\n",
    "negative = load_data(negative_file)\n",
    "\n",
    "print(positive[0:10])\n",
    "print(negative[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yrgEYOOCII4d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Do not modify - Combines the positive and negative reviews into a single list and create labels\n",
    "data = positive + negative\n",
    "word_labels = [\"positive\"] * len(positive) + [\"negative\"] * len(negative) \n",
    "\n",
    "# Converts labels to numbers in one-hot encoding - [1, 0] (positive) or [0, 1] (negative)\n",
    "from keras.utils import to_categorical\n",
    "labels  = to_categorical(to_numeric_label(word_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97Uh2uBpII4l",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews have a mean length of 24.676519799219186 characters and the std deviation of 11.287199941717205\n",
      "Total no. of unique words: 2559 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write some code to investigate the dataset. \n",
    "# - Calculate and report the mean review size, its standard deviation and create a boxplot.\n",
    "# - Calculate the number of unique words in the dataset\n",
    "# - Perform any other dataset investigation that you feel wouldpositive_file be valuable\n",
    "rev_length = [] \n",
    "\n",
    "for x in data:\n",
    "    rev_length.append(len(x))\n",
    "\n",
    "list(map(int, rev_length))\n",
    "rev_length_mean = statistics.mean(rev_length)\n",
    "rev_length_std = statistics.stdev(rev_length)\n",
    "\n",
    "print(\"Reviews have a mean length of {} characters and the std deviation of {}\".format(rev_length_mean,rev_length_std))\n",
    "\n",
    "word_list = ' '.join(data)\n",
    "\n",
    "word_count = len(set(re.findall('\\w+', word_list.lower())))\n",
    "\n",
    "print(\"Total no. of unique words: {} \".format(word_count))\n",
    "fig = plt.figure(figsize =(10, 7)) \n",
    "  \n",
    "# Creating plot \n",
    "plt.boxplot(rev_length) \n",
    "  \n",
    "# show plot \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "_XXnArgcII4i",
    "outputId": "020b2ee2-4c2a-4bc0-bb55-e2ae3841fe57",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one of the best crichton novels', 'the medicine of the future', 'beautiful', 'for lovers of robicheaux', 'a good book']\n",
      "[[18, 4, 2, 19], [2, 4, 2], [], [6, 4], [1, 12, 3]]\n"
     ]
    }
   ],
   "source": [
    "# Do not modify - Tokenize the vocabulary \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=25)\n",
    "\n",
    "tokenizer.fit_on_texts(data) #create the vocabularry\n",
    "\n",
    "tokenized_data = tokenizer.texts_to_sequences(data) #tokenize the data using the vocabulary\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1 \n",
    "\n",
    "# Compare a sample of the data before and after tokenization\n",
    "print(data[0:5])\n",
    "print(tokenized_data[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_vsMmLjdK1Gf"
   },
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "24DaXd1zII4q",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pre-processing\n",
    "# Write some code to pre-process the data so that each review is the same length\n",
    "padded = pad_sequences(sequences=tokenized_data, maxlen=round(rev_length_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AFTJcFy6II4s",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write some code to split the data into a training and test set. Make sure you shuffle the data. Use 20% for the test set.\n",
    "\n",
    "X = padded\n",
    "y = labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=y, random_state=4)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, shuffle=y, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "lDth1BSzII4u",
    "outputId": "4614049a-7151-4407-9bc8-54604bbe7fdd"
   },
   "outputs": [],
   "source": [
    "# Fill in the following function so it\n",
    "# - makes a prediction for the test set given the model\n",
    "# - reports the precision, recall and f1 score. Also print the confusion matrix. \n",
    "# You will need to use the helper to_class function to convert y_pred and y_test before supplying them to the sklearn functions.\n",
    "\n",
    "def assess_model(model, X_test, y_test):      \n",
    "    #To do\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(26, 64, input_length=round(rev_length_mean)))\n",
    "    model.compile('rmsprop', 'mse')\n",
    "    y_pred = model.predict(X_test)\n",
    "   \n",
    "\n",
    "    disp = metrics.plot_confusion_matrix(model, X_test, y_test.to_class)\n",
    "    disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "    \n",
    "    plt.show()\n",
    "    print(metrics.classification_report(y_test.to_class, y_pred.to_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nTqLbbE6MpGt"
   },
   "source": [
    "# Build and tune model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3X70rA4uMXNv"
   },
   "source": [
    "Define network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wKoXWKG4II5F"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(26, 64, input_length=round(rev_length_mean)))\n",
    "model.compile('rmsprop', 'mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "llS0-VKBMbz-"
   },
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F5IJs0QuMe_I"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.train' has no attribute 'AdamOptimizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-cb2f3f0a9d30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Compiling the model adds a loss function, optimiser and metrics to track during training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m model.compile(optimizer=tf.train.AdamOptimizer(),\n\u001b[0m\u001b[0;32m      6\u001b[0m               \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_categorical_crossentropy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m               metrics=['accuracy'])\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.train' has no attribute 'AdamOptimizer'"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 10\n",
    "\n",
    "# Compiling the model \n",
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(x=X_test, \n",
    "          y=y_test, \n",
    "          batch_size=batch_size, \n",
    "          epochs=num_epochs, \n",
    "          validation_data=(X_val, y_val))\n",
    "\n",
    "print('Training complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rniBBEiyMRKD"
   },
   "source": [
    "Examine performance of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eBVogHg2II5T",
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-7ab04d47d6b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0massess_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmetric_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Final TEST performance'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-f628c126157e>\u001b[0m in \u001b[0;36massess_model\u001b[1;34m(model, X_test, y_test)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mdisp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mdisp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Confusion Matrix\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "assess_model(model, X_test, y_test)\n",
    "\n",
    "metric_values = model.evaluate(x=X_test, y=y_test)\n",
    "\n",
    "print('TEST performance')\n",
    "for metric_value, metric_name in zip(metric_values, model.metrics_names):\n",
    "  print('{}: {}'.format(metric_name, metric_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HB8kzt-IME4U"
   },
   "source": [
    "Plot graphs for accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hPyJ78unMJUI"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-1469ea8bab00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloss_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mloss_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m35\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'g'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Training loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'validation loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "loss_train = model.history['train_loss']\n",
    "loss_val = model.history['val_loss']\n",
    "epochs = range(1,35)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eAZ1LyFBMLoK"
   },
   "source": [
    "# Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vfPM5LokII5V",
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'maxlen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-44de942821f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprediction_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"this book is fabulous\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"i hated this book\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"the best\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"no good\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"okay\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtokenized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpadded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'post'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Supply this data to each of your models and see how it does.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'maxlen' is not defined"
     ]
    }
   ],
   "source": [
    "# This is a very small set of completed new data to use to make predictions.\n",
    "prediction_data = [\"this book is fabulous\",\"i hated this book\", \"the best\", \"no good\", \"okay\"]\n",
    "tokenized = tokenizer.texts_to_sequences(prediction_data)\n",
    "padded = pad_sequences(tokenized, padding='post', maxlen=maxlen)\n",
    "\n",
    "# Supply this data to each of your models and see how it does. \n",
    "# You can call the helper function \"to_word_label\" to map the output of the model to the name of the\n",
    "# class it was predicted to belong to.\n",
    "\n",
    "assess_model(model, tokenized, padded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "L3T20.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
